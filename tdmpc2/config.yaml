defaults:
    - override hydra/launcher: submitit_local

# environment
task: dog-run
obs: state
# robosuite specific
rs_env_name: PickPlaceSingle
rs_robots: IIWA
rs_controller: JOINT_TORQUE
rs_max_episode_steps: 200

# evaluation
checkpoint: ???
eval_episodes: 10
eval_freq: 5000
use_tensorboard: True

# training
steps: 10_000_000
batch_size: 256
reward_coef: 0.1
value_coef: 0.1
is_first_coef: 0.1
dynamics_coef: 1
representation_coef: 0.2
rho: 0.5
td_lambda: 0.95
lr: 3e-4
burn_in: 0
enc_lr_scale: 0.3
grad_clip_norm: 1000
tau: 0.01
discount_denom: 5
discount_min: 0.95
discount_max: 0.995
buffer_size: 500_000
exp_name: default
data_dir: ???
dyn_scale: 0.5
rep_scale: 0.1
kl_free: 1.0

# planning
random_policy: false # use this to isolate world model training
mpc: true
iterations: 6
num_samples: 512
num_elites: 64
num_pi_trajs: 24
#horizon: 10
# TODO: use config for these
#num_samples: 64
#num_elites: 8
#num_pi_trajs: 6
horizon: 10
min_std: 0.05
max_std: 2
temperature: 0.5

# actor
log_std_min: -10
log_std_max: 2
entropy_coef: 1e-4

# critic
num_bins: 101
vmin: -10
vmax: +10

# architecture
model_size: ???
num_enc_layers: 2
enc_dim: 256
num_channels: 32
mlp_dim: 512
latent_dim: 512
hidden_dim: 512
task_dim: 96
act: SiLU
norm: true
num_q: 5
dropout: 0.01

# RSSM
simnorm_dim: 8
dyn_mean_act: 'none'
dyn_std_act: 'sigmoid2'
dyn_min_std: 0.1
unimix_ratio: 0.01
initial: 'learned'
dyn_discrete: 32
dyn_stoch: 32
grad_heads: ['reward', 'V']
encoder:
    {mlp_keys: 'state', cnn_keys: 'image', act: 'SiLU', norm: True, cnn_depth: 32, kernel_size: 4, minres: 4, mlp_layers: 5, mlp_units: 1024, symlog_inputs: False}
actor:
    {layers: 2, dist: 'normal', entropy: 3e-4, unimix_ratio: 0.01, std: 'learned', min_std: 0.1, max_std: 1.0, temp: 0.1, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 1.0}
reward_head:
    {layers: 2, dist: 'symlog_disc', loss_scale: 1.0, outscale: 0.0}
V_head:
    {layers: 2, dist: 'symlog_disc', slow_target: True, slow_target_update: 1, slow_target_fraction: 0.02, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 0.0}
is_first_head:
    {layers: 2, loss_scale: 1.0, outscale: 1.0}
# logging
wandb_project: ltc-tdmpc2
wandb_entity: mihaistanusoiu-tu-wien
wandb_silent: false
enable_wandb: true
save_csv: true

# misc
save_video: true
save_agent: true
save_buffer: true
override: true
seed: 1

# convenience
work_dir: ???
task_title: ???
multitask: ???
tasks: ???
obs_shape: ???
action_dim: ???
episode_length: ???
obs_shapes: ???
action_dims: ???
episode_lengths: ???
seed_steps: 100
bin_size: ???

# speedups
compile: False
